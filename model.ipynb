{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "valid_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:12.063696800Z",
     "start_time": "2025-03-20T05:28:11.588983200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'document_id', 'sentence_id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 14041\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:12.169272300Z",
     "start_time": "2025-03-20T05:28:12.132079900Z"
    }
   },
   "id": "dd56079084eb1061"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "num_labels = len(labels)\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:12.423235500Z",
     "start_time": "2025-03-20T05:28:12.414037700Z"
    }
   },
   "id": "51ea8d1dd1221da6"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:12.780582900Z",
     "start_time": "2025-03-20T05:28:12.771334500Z"
    }
   },
   "id": "6e51e05d7d40e757"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForTokenClassification\n",
    "# \n",
    "# model_checkpoint = \"bert-base-cased\"\n",
    "# \n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:13.162247200Z",
     "start_time": "2025-03-20T05:28:13.148533600Z"
    }
   },
   "id": "4dcaf1160f46ce94"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit\n",
    "    data = data[:nbatch * bsz]\n",
    "    # Evenly divide the data across the bsz batches\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:13.564611300Z",
     "start_time": "2025-03-20T05:28:13.557852500Z"
    }
   },
   "id": "880b52fc7e1317e6"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# batch_size = 20\n",
    "# eval_batch_size = 10\n",
    "# \n",
    "# \n",
    "# \n",
    "# # train_data = batchify(train_dataset, batch_size)\n",
    "# # val_data = batchify(valid_dataset, eval_batch_size)\n",
    "# # test_data = batchify(test_dataset, eval_batch_size)\n",
    "# \n",
    "# test = list(train_dataset.values())\n",
    "# print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:14.045491100Z",
     "start_time": "2025-03-20T05:28:14.031244800Z"
    }
   },
   "id": "6916aea53be7d9e1"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:15.560984300Z",
     "start_time": "2025-03-20T05:28:14.486870100Z"
    }
   },
   "id": "1ace5000cd89d09a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6023,  0.1092,  0.1417,  ..., -0.4177,  0.6059,  0.1764],\n",
      "         [ 0.5119, -0.4770,  0.5508,  ..., -0.2814,  0.3793,  0.1156],\n",
      "         [ 0.0995,  0.0867,  0.0869,  ...,  0.4789, -0.3236,  0.3122],\n",
      "         ...,\n",
      "         [ 0.8081, -0.7380,  0.2001,  ...,  0.7405, -0.7998,  0.6449],\n",
      "         [ 0.3305, -0.1958,  0.3148,  ..., -0.0525,  0.5358,  0.1987],\n",
      "         [ 0.5655, -0.2176, -0.4720,  ..., -0.3554,  0.6141, -0.2476]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.2835e-01,  6.0906e-01,  9.9998e-01, -9.9831e-01,  9.8739e-01,\n",
      "          9.2930e-01,  9.9664e-01, -9.8909e-01, -9.9124e-01, -7.8317e-01,\n",
      "          9.9476e-01,  9.9961e-01, -9.9850e-01, -9.9997e-01,  8.0649e-01,\n",
      "         -9.9098e-01,  9.9545e-01, -6.9968e-01, -9.9999e-01, -2.6556e-01,\n",
      "         -4.1867e-01, -9.9998e-01,  3.1562e-01,  9.7638e-01,  9.9257e-01,\n",
      "          1.4021e-01,  9.9543e-01,  9.9999e-01,  9.4214e-01, -2.0248e-01,\n",
      "          3.5963e-01, -9.9665e-01,  8.5152e-01, -9.9975e-01,  2.8570e-01,\n",
      "          7.8626e-03,  8.4606e-01, -3.7096e-01,  7.4315e-01, -9.5596e-01,\n",
      "         -7.8807e-01, -4.7754e-01,  6.0904e-01, -6.4658e-01,  9.6723e-01,\n",
      "          2.2952e-01,  2.4267e-01,  1.1464e-01, -1.1224e-01,  9.9997e-01,\n",
      "         -9.9227e-01,  9.9995e-01, -9.9455e-01,  9.9951e-01,  9.9903e-01,\n",
      "          4.6473e-01,  9.9825e-01,  1.8630e-01, -9.9897e-01,  4.2824e-01,\n",
      "          9.7877e-01,  9.9492e-02,  9.7601e-01, -2.5574e-01, -1.0145e-01,\n",
      "         -5.6067e-01, -8.6941e-01,  2.3935e-01, -6.2682e-01,  5.1608e-01,\n",
      "          4.8575e-01,  4.8747e-01,  9.9565e-01, -9.5639e-01, -1.1690e-01,\n",
      "         -9.4263e-01,  1.5285e-01, -9.9998e-01,  9.8651e-01,  9.9999e-01,\n",
      "          6.5605e-01, -9.9991e-01,  9.9870e-01, -4.0475e-01, -7.0561e-01,\n",
      "          2.7477e-01, -9.9917e-01, -9.9987e-01,  1.8895e-01, -6.6828e-01,\n",
      "          8.3371e-01, -9.9579e-01,  5.4993e-01, -9.1550e-01,  1.0000e+00,\n",
      "         -9.6308e-01, -2.8974e-01,  4.9713e-01,  9.5074e-01, -3.1329e-01,\n",
      "         -8.5073e-01,  9.2660e-01,  9.9924e-01, -9.9509e-01,  9.9877e-01,\n",
      "          5.7332e-01, -9.5204e-01, -8.4878e-01,  5.3101e-01,  2.2957e-01,\n",
      "          9.9633e-01, -9.9581e-01, -8.4645e-01,  2.3134e-01,  9.7124e-01,\n",
      "         -7.6645e-01,  9.9707e-01,  7.0794e-01, -4.3663e-01,  1.0000e+00,\n",
      "         -2.7179e-01,  9.8517e-01,  9.9961e-01,  9.0877e-01, -8.1168e-01,\n",
      "         -3.3681e-01, -4.8113e-01,  8.1254e-01, -3.3984e-01, -5.0071e-01,\n",
      "          8.5569e-01, -9.9618e-01, -9.9880e-01,  9.9988e-01, -3.4080e-01,\n",
      "          9.9999e-01, -9.9978e-01,  9.9567e-01, -9.9999e-01, -5.9676e-01,\n",
      "         -8.0271e-01, -1.6363e-02, -9.9063e-01,  2.9677e-01,  9.9670e-01,\n",
      "          1.9180e-01, -9.6363e-01, -6.3803e-01,  4.5937e-01, -8.5751e-01,\n",
      "          6.9634e-01,  8.6684e-01, -9.8712e-01,  9.9985e-01,  9.9661e-01,\n",
      "          9.6512e-01,  9.9064e-01,  3.0494e-01, -9.6835e-01,  8.8074e-01,\n",
      "          9.9611e-01, -9.9987e-01,  5.6770e-01, -9.9339e-01,  9.9983e-01,\n",
      "          9.9128e-01,  6.8117e-01, -9.9564e-01,  9.9998e-01, -4.5610e-01,\n",
      "          2.2760e-01, -1.9633e-01, -4.2445e-01, -9.9918e-01,  6.1411e-01,\n",
      "          5.4706e-01,  8.1350e-01,  9.9991e-01, -9.9806e-01,  9.9992e-01,\n",
      "          9.9405e-01, -2.4961e-01,  8.3604e-01,  9.9859e-01, -9.9852e-01,\n",
      "         -9.9445e-01, -9.9634e-01,  3.6493e-01,  5.9082e-01,  4.1785e-01,\n",
      "          4.1630e-01,  9.7932e-01,  9.9917e-01,  8.1510e-01, -9.9967e-01,\n",
      "         -4.6312e-01,  9.9122e-01, -2.8691e-01,  1.0000e+00,  2.9178e-01,\n",
      "         -9.9996e-01, -8.2507e-01,  9.6417e-01,  9.9644e-01, -4.4478e-01,\n",
      "          9.9324e-01, -5.7101e-01, -3.4857e-04,  9.8806e-01, -9.9977e-01,\n",
      "          9.9852e-01, -2.3978e-01,  8.4522e-01,  9.3744e-01,  9.9795e-01,\n",
      "         -8.0662e-01, -2.2260e-01,  3.8672e-01, -6.8129e-01,  9.9997e-01,\n",
      "         -9.9990e-01, -3.2183e-01,  5.9251e-01, -9.9829e-01, -9.9941e-01,\n",
      "          9.9586e-01, -1.0074e-01, -7.3508e-01, -2.5186e-01,  1.9904e-01,\n",
      "          3.7265e-01,  9.1428e-01,  9.9669e-01, -5.9080e-01, -2.5383e-01,\n",
      "         -9.9996e-01, -9.9760e-01, -8.7478e-01, -9.7038e-01,  2.0462e-01,\n",
      "          8.0368e-01, -5.2217e-01, -9.6130e-01, -9.9889e-01,  9.9059e-01,\n",
      "          6.4181e-01, -9.2359e-01, -5.0590e-01, -5.2063e-01, -9.9898e-01,\n",
      "          3.8437e-01, -8.1184e-01, -9.9977e-01,  9.9992e-01, -8.2068e-01,\n",
      "          9.9730e-01,  9.9512e-01, -9.9856e-01,  7.3626e-01, -9.9888e-01,\n",
      "         -7.3231e-03, -9.9984e-01,  1.2394e-01,  3.3718e-01, -7.3533e-01,\n",
      "         -8.3841e-02,  9.9802e-01, -9.8660e-01, -8.3092e-01,  8.1347e-01,\n",
      "         -9.9999e-01,  9.7834e-01, -3.6798e-01,  9.9975e-01,  7.8506e-01,\n",
      "         -7.4606e-02,  9.9465e-01,  9.3201e-01, -9.9514e-01, -9.9995e-01,\n",
      "          8.7159e-01,  9.9806e-01, -9.9809e-01, -3.5480e-01,  9.9999e-01,\n",
      "         -9.9877e-01, -8.3069e-01, -9.7494e-01, -9.9894e-01, -9.9993e-01,\n",
      "          1.5644e-01, -7.8414e-01,  6.0187e-02,  9.9392e-01,  2.4572e-01,\n",
      "          1.6016e-01,  9.9910e-01,  9.9941e-01,  2.2788e-01,  8.4298e-03,\n",
      "          1.5305e-01, -9.9167e-01, -9.9933e-01,  6.4604e-01,  3.7302e-01,\n",
      "         -9.9999e-01,  9.9997e-01, -9.9826e-01,  9.9987e-01,  9.6995e-01,\n",
      "         -9.9343e-01,  8.8091e-01,  1.4430e-02, -9.6750e-01,  1.0024e-01,\n",
      "          9.9998e-01,  9.9338e-01, -1.5025e-01,  3.1323e-01,  9.1669e-01,\n",
      "         -2.1946e-01,  4.9523e-01, -7.6086e-01, -5.7688e-01,  2.3562e-01,\n",
      "         -9.6419e-01,  9.9618e-01,  6.4859e-01, -9.9733e-01,  9.9700e-01,\n",
      "          6.5070e-02,  8.3284e-01, -7.4301e-01,  9.1747e-01,  9.9662e-01,\n",
      "         -2.7177e-01, -3.7245e-01, -4.3213e-02, -9.3129e-01, -9.7803e-01,\n",
      "          2.7836e-01, -9.9750e-01, -3.2621e-01,  9.6046e-01,  9.9694e-01,\n",
      "         -9.9700e-01,  9.9945e-01, -3.0036e-01,  8.7511e-01, -9.9853e-01,\n",
      "          1.0000e+00, -9.9977e-01,  2.8375e-01,  5.8693e-01, -9.1986e-01,\n",
      "         -5.8613e-01,  9.9782e-01,  9.8489e-01,  9.7992e-01, -8.6434e-01,\n",
      "         -4.6918e-01,  9.2471e-01,  9.9000e-01, -9.8676e-01,  5.5841e-02,\n",
      "         -9.9959e-01, -6.3961e-01,  9.9900e-01,  9.9601e-01, -1.8137e-01,\n",
      "         -5.7472e-01, -9.9791e-01,  9.8469e-01, -8.4956e-01, -7.2607e-01,\n",
      "         -1.8493e-01, -8.4716e-01,  5.6414e-01,  9.9854e-01, -2.8356e-01,\n",
      "          5.9711e-01,  2.0103e-01, -9.9755e-01,  8.3863e-01,  6.8787e-01,\n",
      "          9.9996e-01, -9.9299e-01,  3.1409e-01,  9.9636e-01, -3.3831e-01,\n",
      "         -6.6649e-01,  7.4109e-01,  9.9907e-01, -9.8940e-01, -3.6638e-01,\n",
      "         -9.9990e-01,  4.8964e-02, -8.5911e-01,  1.4593e-01, -2.9822e-01,\n",
      "          2.2590e-01, -8.4246e-01,  9.6926e-01,  1.0953e-01,  8.4557e-01,\n",
      "         -5.9910e-03,  9.8803e-01, -2.0996e-02, -1.0543e-01, -4.6601e-01,\n",
      "         -4.2787e-02,  6.1662e-01,  1.2547e-01,  9.9180e-01, -9.9351e-01,\n",
      "          9.9996e-01, -6.7802e-01, -9.9999e-01, -9.9770e-01, -5.7405e-01,\n",
      "         -9.9994e-01,  6.3853e-01, -9.9951e-01,  9.9676e-01,  9.6816e-01,\n",
      "         -9.9848e-01, -9.9946e-01, -9.9982e-01, -9.9976e-01,  6.1510e-01,\n",
      "          6.4182e-01, -2.1805e-01,  9.2797e-02,  9.0330e-01,  1.4380e-01,\n",
      "          1.2573e-01, -1.0409e-01, -9.7871e-01, -4.2303e-01, -9.9905e-01,\n",
      "          7.1276e-01, -9.9999e-01, -6.9909e-01,  9.9814e-01, -9.9562e-01,\n",
      "         -9.4415e-01, -9.6432e-01, -8.9964e-01, -9.2392e-01,  5.7695e-01,\n",
      "          9.9405e-01, -1.8583e-01, -5.1823e-01, -9.9992e-01,  9.9637e-01,\n",
      "         -8.6311e-01,  1.3339e-01, -8.4187e-01, -9.9070e-01,  9.9994e-01,\n",
      "          8.9447e-01, -1.2484e-01, -2.5460e-01, -9.9981e-01,  9.9253e-01,\n",
      "         -9.3657e-01, -9.1491e-01, -9.9574e-01,  3.4290e-01, -9.7082e-01,\n",
      "         -9.9998e-01,  1.6956e-01,  9.9788e-01,  9.9939e-01,  9.8977e-01,\n",
      "          1.9435e-01, -4.6757e-01, -9.7244e-01,  3.6547e-01, -9.9999e-01,\n",
      "          8.2877e-01,  8.5028e-01, -9.9369e-01, -5.5643e-01,  9.9792e-01,\n",
      "          9.9398e-01, -9.6296e-01, -9.8676e-01,  9.4785e-01,  7.4835e-01,\n",
      "          9.7754e-01, -3.5312e-01, -4.9721e-01,  4.5349e-01, -1.5718e-01,\n",
      "         -9.9632e-01, -9.8159e-01,  9.9876e-01, -9.9932e-01,  9.8976e-01,\n",
      "          9.9815e-01,  9.9910e-01,  2.7285e-01, -1.3299e-01, -9.9287e-01,\n",
      "         -9.9943e-01, -6.8430e-01,  3.2410e-01, -9.9999e-01,  9.9998e-01,\n",
      "         -1.0000e+00,  5.1310e-01, -6.4679e-01,  9.0606e-01,  9.9615e-01,\n",
      "         -3.3432e-01, -9.9998e-01, -9.9997e-01,  8.6537e-01, -3.1250e-01,\n",
      "          9.9661e-01,  2.3914e-01,  3.9441e-01, -5.5191e-01, -2.8731e-02,\n",
      "          9.9953e-01, -9.4059e-01, -6.8058e-01, -9.9860e-01,  9.9991e-01,\n",
      "          7.7975e-01, -9.9972e-01,  9.9650e-01, -9.9993e-01,  8.6067e-01,\n",
      "          9.9085e-01,  9.5399e-01,  9.9253e-01, -9.9939e-01,  1.0000e+00,\n",
      "         -9.9996e-01,  9.9958e-01, -9.9999e-01, -9.9914e-01,  9.9996e-01,\n",
      "         -9.9680e-01, -5.2242e-01, -9.9995e-01, -9.9846e-01,  7.6624e-01,\n",
      "          3.0813e-01, -6.0101e-01,  9.9681e-01, -9.9996e-01, -9.9965e-01,\n",
      "          5.0632e-01, -9.5096e-01, -7.7078e-01,  9.9660e-01, -5.1192e-01,\n",
      "          9.9864e-01, -1.3044e-02,  9.8215e-01,  1.4195e-01,  9.9789e-01,\n",
      "          9.9982e-01, -6.5892e-01, -4.9805e-01, -9.9783e-01,  9.9263e-01,\n",
      "         -6.6011e-01,  4.8956e-01,  9.8212e-01, -1.5472e-01, -4.5557e-01,\n",
      "          5.7543e-01, -9.9919e-01,  5.2152e-01, -8.3201e-01,  8.9039e-01,\n",
      "          9.4857e-01,  9.1789e-01,  1.1048e-02, -3.8681e-01, -1.1080e-01,\n",
      "         -9.9808e-01,  7.4150e-01, -9.9987e-01,  9.9106e-01, -9.6465e-01,\n",
      "          2.9540e-01, -5.3421e-01,  5.4674e-01, -9.7558e-01,  9.9991e-01,\n",
      "          9.9965e-01, -9.9994e-01,  2.2361e-01,  9.9665e-01, -6.4159e-01,\n",
      "          9.9177e-01, -9.9753e-01, -6.9763e-02,  9.6400e-01, -8.7434e-01,\n",
      "          9.9381e-01,  1.8743e-01, -2.3633e-01,  9.8364e-01, -9.9887e-01,\n",
      "         -9.0222e-01, -7.9110e-01,  3.5238e-01,  3.4325e-01, -9.8982e-01,\n",
      "          2.8097e-01,  9.8251e-01,  7.6614e-02, -9.9993e-01,  9.8067e-01,\n",
      "         -9.9986e-01, -3.6354e-01,  9.9292e-01,  1.4346e-01,  9.9998e-01,\n",
      "         -7.4159e-01,  3.1454e-02,  1.0397e-01, -9.9994e-01, -9.9913e-01,\n",
      "          2.1931e-01, -2.7733e-01, -9.5555e-01,  9.9938e-01, -5.0607e-02,\n",
      "          8.3410e-01, -9.9998e-01,  4.2417e-01,  9.9698e-01,  3.9198e-01,\n",
      "          9.1816e-01, -8.0208e-01, -9.7382e-01, -9.5518e-01, -6.6141e-01,\n",
      "          1.5180e-01,  9.0137e-01, -9.9532e-01, -9.1342e-01, -7.1074e-01,\n",
      "          9.9999e-01, -9.9956e-01, -9.7606e-01, -9.9647e-01,  4.1117e-01,\n",
      "          8.8649e-01,  6.1946e-01,  1.1032e-01, -8.1373e-01,  9.3144e-01,\n",
      "         -9.1679e-01,  9.9910e-01, -9.9854e-01, -9.9933e-01,  9.9996e-01,\n",
      "          6.8804e-01, -9.9306e-01, -1.1649e-01, -4.1921e-01,  7.9799e-02,\n",
      "         -6.4763e-03,  7.7816e-01, -9.5855e-01, -2.6136e-01, -9.9975e-01,\n",
      "          8.5560e-01, -8.4889e-01, -9.9709e-01, -6.7251e-01, -4.8243e-01,\n",
      "         -9.9988e-01,  9.9809e-01,  9.9115e-01,  9.9999e-01, -9.9996e-01,\n",
      "          8.7347e-01,  2.2774e-01,  9.9976e-01,  4.1655e-02, -7.7174e-01,\n",
      "          9.2765e-01,  9.9992e-01, -7.4625e-01,  7.7272e-01,  1.8972e-02,\n",
      "         -2.1511e-01,  4.3176e-02, -7.1345e-01,  9.9652e-01, -9.4827e-01,\n",
      "          3.5106e-01, -9.9568e-01, -9.9998e-01,  9.9999e-01, -1.2416e-01,\n",
      "          9.9711e-01,  3.3779e-01,  8.0375e-01, -8.9710e-01,  9.8400e-01,\n",
      "         -9.8929e-01, -9.3701e-01, -1.0000e+00,  2.1380e-01, -9.9995e-01,\n",
      "         -9.9693e-01,  2.9115e-01,  9.9771e-01, -9.9989e-01, -9.9722e-01,\n",
      "         -3.7007e-01, -1.0000e+00,  9.1409e-01, -9.9338e-01, -7.9647e-01,\n",
      "         -9.9685e-01,  9.9875e-01, -5.3951e-01, -4.7717e-01,  9.9424e-01,\n",
      "         -9.9099e-01,  9.3857e-01,  9.7499e-01,  7.2225e-01,  2.9207e-01,\n",
      "          3.1667e-01, -6.4539e-01, -9.9575e-01, -9.5048e-01, -9.8199e-01,\n",
      "          9.2237e-01, -9.9711e-01, -9.4075e-01,  9.9913e-01,  9.9735e-01,\n",
      "         -9.9988e-01, -9.9907e-01,  9.9719e-01, -2.8665e-01,  9.9731e-01,\n",
      "         -6.8889e-01, -9.9997e-01, -9.9998e-01,  1.8779e-01, -2.7697e-01,\n",
      "          9.9849e-01, -4.6101e-01,  9.9961e-01,  8.1148e-01, -8.5870e-02,\n",
      "          4.4598e-01, -3.9436e-01, -1.2326e-01, -2.3773e-01, -2.7982e-01,\n",
      "          9.9999e-01, -4.9552e-01,  9.9713e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:28:15.578801800Z",
     "start_time": "2025-03-20T05:28:15.561984800Z"
    }
   },
   "id": "e3bd30ac1b4f36d1"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.9990139), 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': np.float32(0.999645), 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "print(device)\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:47:11.121992300Z",
     "start_time": "2025-03-20T05:47:10.187755800Z"
    }
   },
   "id": "aab526785c81681a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
      "J\n",
      "bert ner: J\n",
      "true: SOCCER\n",
      "bert ner: ##AP\n",
      "true: CHINA\n",
      "bert ner: L\n",
      "true: CHINA\n",
      "bert ner: ##UC\n",
      "true: CHINA\n",
      "bert ner: CH\n",
      "true: CHINA\n",
      "bert ner: ##IN\n",
      "true: CHINA\n",
      "bert ner: ##A\n",
      "true: CHINA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "count = 0\n",
    "total = len(test_dataset)\n",
    "for data in test_dataset:\n",
    "    seq = \" \".join([token for token in data['tokens']])\n",
    "    ner_results = nlp(seq)\n",
    "    j = 0\n",
    "    print(seq)\n",
    "    print(ner_results[0]['word'])\n",
    "    for i in range(len(ner_results)):\n",
    "        print(\"bert ner:\",ner_results[i]['word'])\n",
    "        print(\"true:\", data['tokens'][j])\n",
    "        while j < len(ner_results):\n",
    "            if ner_results[i]['word'] == data['tokens'][j]:\n",
    "                if ner_results[i]['entity'] == data['ner_tags'][j]:\n",
    "                    print(\"bert ner:\",ner_results[i]['word'])\n",
    "                    count += 1\n",
    "            j += 1\n",
    "    break\n",
    "        # print(ner_results[i]['entity'])\n",
    "        # print(data)\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:47:12.260047400Z",
     "start_time": "2025-03-20T05:47:12.229524400Z"
    }
   },
   "id": "5aac1ac37197fa9f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(count/total)\n",
    "print(count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:29:44.105928800Z",
     "start_time": "2025-03-20T05:29:44.094087700Z"
    }
   },
   "id": "2d191b1c3c785ec9"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': np.float32(0.9990139), 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': np.float32(0.999645), 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T05:39:19.913337600Z",
     "start_time": "2025-03-20T05:39:18.735478800Z"
    }
   },
   "id": "ae5f743c343bdd24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4d46480dfba19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
